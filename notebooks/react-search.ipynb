{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3e05766-7fab-486c-815b-67c496095967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "from pydantic import Field\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.tools.types import BaseTool\n",
    "from llama_index.llms.bedrock_converse import BedrockConverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e282f04e-46e1-46df-8614-94b522e80da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a22794fc-314d-4ecd-8db8-ceced046ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID=os.environ.get(\"MODEL_ID\", \"anthropic.claude-3-haiku-20240307-v1:0\")\n",
    "AWS_PROFILE_NAME=os.environ.get(\"AWS_PROFILE_NAME\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22321b90-6b0e-4d96-9a6b-3e02f94a00a8",
   "metadata": {},
   "source": [
    "### Setup tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bb474fe-48f9-4192-b7e8-67c4fee1d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(\n",
    "    date: str = Field(\n",
    "        description=\"A date, formmated in RFC3999\",\n",
    "    ),\n",
    "    location: str = Field(\n",
    "        description=\"A city name and state, formatted like '<name>, <state>'\"\n",
    "    ),\n",
    ") -> str:\n",
    "    \"\"\"Usfeful for getting the weather for a given location.\"\"\"\n",
    "    return f\"Weather in {location}, {date} is great!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c454a5c-74a4-4b6a-9e30-8cf1279546a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup tools\n",
    "tools: list[BaseTool] = [\n",
    "    FunctionTool.from_defaults(get_weather),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd639b2f-b4fc-4fb6-89d1-b06ab5ca8533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup llm\n",
    "llm = BedrockConverse(\n",
    "    model=MODEL_ID,\n",
    "    max_tokens=1024 * 2,\n",
    "    temperature=0.4,\n",
    "    profile_name=AWS_PROFILE_NAME,\n",
    ")\n",
    "\n",
    "# setup agent\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2173a4a-5bda-4660-a38e-77306be321a0",
   "metadata": {},
   "source": [
    "### Agent prompt\n",
    "\n",
    "https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/agent/react/templates/system_header_template.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ee9b9fb-33c1-4e3a-b706-84fcb8b417aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "{tool_desc}\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of {tool_names}) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(agent.get_prompts()['agent_worker:system_prompt'].template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4607d90-f15d-4f57-8252-df319fff1b13",
   "metadata": {},
   "source": [
    "### Invoke agent with tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7890d3b1-1850-497b-b839-fd251092a06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 34665c08-c580-40da-b12d-f635020c0d09. Step input: 2024-10-17 수원 날씨는 어때?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: Korean. I need to use a tool to help me answer the question.\n",
      "Action: get_weather\n",
      "Action Input: {'date': '2024-10-17', 'location': '수원'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Weather in 수원, 2024-10-17 is great!\n",
      "\u001b[0m> Running step d007ad02-9342-4e8a-b13f-a5806087770d. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: 2024년 10월 17일 수원의 날씨는 좋습니다.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "resp = agent.chat(\n",
    "    \"2024-10-17 수원 날씨는 어때?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76090ed-77f2-44d2-ad0b-9646c1ebf601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70252cc-35bc-4e0b-8dbe-428b265b45fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
